import streamlit as st
import pandas as pd
import yaml
import os
from utils._schema_manager import SchemaManager
from utils._validator import DataValidator
from utils._previewer import DataPreviewer
from utils._uploader import DataUploader
from utils._s3_history import S3HistoryManager
from utils._normalizer import ColumnNormalizer

def main():
    st.set_page_config(
        page_title="Sistema de Upload de Arquivos",
        page_icon="üìÅ",
        layout="wide"
    )
    
    st.title("üìÅ Sistema de Upload de Arquivos")
    st.markdown("Upload e valida√ß√£o de arquivos CSV/Excel com schemas configur√°veis")
    
    # Sidebar para configura√ß√µes
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")
        
        # Schema selection
        schema_manager = SchemaManager()
        schemas = schema_manager.list_schemas()
        
        if not schemas:
            st.error("Nenhum schema encontrado na pasta 'schema/'")
            return
            
        selected_schema = st.selectbox(
            "Selecione o Schema:",
            options=schemas,
            format_func=lambda x: x.replace('.yaml', '').replace('_', ' ').title()
        )
        
        # S3 Configuration
        st.subheader("üóÑÔ∏è Configura√ß√£o S3")
        aws_access_key = st.text_input("AWS Access Key", type="password")
        aws_secret_key = st.text_input("AWS Secret Key", type="password") 
        bucket_name = st.text_input("Bucket Name", value="meu-bucket-dados")
        aws_region = st.text_input("AWS Region", value="us-east-1")

    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üì§ Upload de Arquivo")
        
        # File upload
        uploaded_file = st.file_uploader(
            "Escolha um arquivo CSV ou Excel",
            type=['csv', 'xlsx', 'xls'],
            help="Formatos suportados: CSV, Excel (.xlsx, .xls)"
        )
        
        if uploaded_file is not None:
            # Load schema
            schema_data = schema_manager.load_schema(selected_schema)
            if not schema_data:
                st.error(f"Erro ao carregar schema: {selected_schema}")
                return
                
            # Preview file
            previewer = DataPreviewer()
            df = previewer.preview_file(uploaded_file)
            
            if df is not None:
                st.subheader("üëÄ Preview dos Dados")
                st.dataframe(df.head(10), use_container_width=True)
                
                st.info(f"üìä **Informa√ß√µes do arquivo:**\n"
                       f"- Linhas: {len(df):,}\n"
                       f"- Colunas: {len(df.columns):,}\n"
                       f"- Tamanho: {uploaded_file.size:,} bytes")
                
                # Normalize columns
                normalizer = ColumnNormalizer()
                original_columns = df.columns.tolist()
                df_normalized = normalizer.normalize_dataframe(df)
                
                if original_columns != df_normalized.columns.tolist():
                    st.subheader("üîÑ Normaliza√ß√£o de Colunas")
                    col_mapping = dict(zip(original_columns, df_normalized.columns.tolist()))
                    
                    mapping_df = pd.DataFrame([
                        {"Coluna Original": orig, "Coluna Normalizada": norm}
                        for orig, norm in col_mapping.items()
                    ])
                    st.dataframe(mapping_df, use_container_width=True)
                
                # Validate data
                validator = DataValidator()
                is_valid, validation_report = validator.validate_data(df_normalized, schema_data)
                
                st.subheader("‚úÖ Valida√ß√£o dos Dados")
                
                if is_valid:
                    st.success("‚úÖ Dados v√°lidos! Pronto para upload.")
                    
                    # Upload section
                    if st.button("üöÄ Fazer Upload para S3", type="primary"):
                        if all([aws_access_key, aws_secret_key, bucket_name]):
                            uploader = DataUploader(
                                aws_access_key=aws_access_key,
                                aws_secret_key=aws_secret_key,
                                bucket_name=bucket_name,
                                region_name=aws_region
                            )
                            
                            with st.spinner("Fazendo upload..."):
                                success, message = uploader.upload_to_s3(
                                    df_normalized, 
                                    uploaded_file.name,
                                    schema_data
                                )
                                
                            if success:
                                st.success(f"‚úÖ {message}")
                                st.rerun()  # Refresh to update history
                            else:
                                st.error(f"‚ùå {message}")
                        else:
                            st.error("‚ö†Ô∏è Por favor, configure todas as credenciais do S3")
                            
                else:
                    st.error("‚ùå Dados inv√°lidos. Verifique os erros abaixo:")
                    
                    for column, errors in validation_report.items():
                        if errors:
                            st.error(f"**{column}**: {', '.join(errors)}")
                    
                    # Allow schema selection for invalid data
                    st.subheader("üîß Tentar com outro Schema")
                    st.info("Os dados n√£o passaram na valida√ß√£o. Voc√™ pode tentar com um schema diferente:")
                    
                    alternative_schemas = [s for s in schemas if s != selected_schema]
                    if alternative_schemas:
                        alternative_schema = st.selectbox(
                            "Selecione um schema alternativo:",
                            options=alternative_schemas,
                            format_func=lambda x: x.replace('.yaml', '').replace('_', ' ').title(),
                            key="alternative_schema"
                        )
                        
                        if st.button("üîÑ Validar com Schema Alternativo"):
                            alt_schema_data = schema_manager.load_schema(alternative_schema)
                            if alt_schema_data:
                                alt_is_valid, alt_validation_report = validator.validate_data(df_normalized, alt_schema_data)
                                
                                if alt_is_valid:
                                    st.success(f"‚úÖ Dados v√°lidos com o schema '{alternative_schema}'!")
                                    
                                    if st.button("üöÄ Upload com Schema Alternativo", type="primary", key="alt_upload"):
                                        if all([aws_access_key, aws_secret_key, bucket_name]):
                                            uploader = DataUploader(
                                                aws_access_key=aws_access_key,
                                                aws_secret_key=aws_secret_key,
                                                bucket_name=bucket_name,
                                                region_name=aws_region
                                            )
                                            
                                            with st.spinner("Fazendo upload..."):
                                                success, message = uploader.upload_to_s3(
                                                    df_normalized, 
                                                    uploaded_file.name,
                                                    alt_schema_data
                                                )
                                                
                                            if success:
                                                st.success(f"‚úÖ {message}")
                                                st.rerun()
                                            else:
                                                st.error(f"‚ùå {message}")
                                        else:
                                            st.error("‚ö†Ô∏è Configure as credenciais do S3")
                                else:
                                    st.error(f"‚ùå Dados tamb√©m inv√°lidos com o schema '{alternative_schema}'")
                                    for column, errors in alt_validation_report.items():
                                        if errors:
                                            st.error(f"**{column}**: {', '.join(errors)}")
    
    with col2:
        st.header("üìú Hist√≥rico de Uploads")
        
        if all([aws_access_key, aws_secret_key, bucket_name]):
            history_manager = S3HistoryManager(
                aws_access_key=aws_access_key,
                aws_secret_key=aws_secret_key,
                bucket_name=bucket_name,
                region_name=aws_region
            )
            
            with st.spinner("Carregando hist√≥rico..."):
                history_df = history_manager.get_upload_history()
            
            if history_df is not None and not history_df.empty:
                st.dataframe(
                    history_df,
                    use_container_width=True,
                    column_config={
                        "upload_date": st.column_config.DatetimeColumn(
                            "Data Upload",
                            format="DD/MM/YYYY HH:mm"
                        ),
                        "file_size_mb": st.column_config.NumberColumn(
                            "Tamanho (MB)",
                            format="%.2f MB"
                        )
                    }
                )
                
                st.info(f"üìä **Total de arquivos**: {len(history_df)}")
            else:
                st.info("Nenhum arquivo encontrado no hist√≥rico")
        else:
            st.info("Configure as credenciais do S3 para ver o hist√≥rico")

if __name__ == "__main__":
    main() 